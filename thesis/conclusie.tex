\chapter{Conclusie \& toekomstig werk}\label{ch:conclusie}
In deze masterproef hebben we verschillende opties verkend om de huidige Unipept index voor UniProtKB te vervangen.
Hierbij lag de hoofdfocus op het vinden van een nieuwe indexstructuur die aan volgende opties voldoet:
\begin{enumerate}
    \item De index moet het mogelijk maken om arbitraire peptiden te kunnen zoeken.
    \item Het geheugenverbruik van de index moet beperkt zijn, zodat het mogelijk is niet enkel kleinere proteïnedatabanken te indexeren, maar ook de volledige UniProtKB databank.
    \item De indexstructuur moet semi-exacte matching ondersteunen, zodat I en L aan elkaar gelijkgesteld kunnen worden.
    \item De indexstructuur moet de taxonomische en functionele analyse van Unipept ondersteunen.
\end{enumerate}

\section{Conclusie}
Een eerste indexstructuur die we bekekenen hebben waren \textbf{suffixbomen}.
Hierbij hebben we een eigen Rust implementatie gemaakt van het algoritme van Ukkonen.
Suffixbomen bieden een extreem grote vrijheid, en het zoeken gaat bovendien extreem snel.
Ze zijn echter \textbf{onbruikbaar} om grote proteïnedatabanken te indexeren vanwege hun \textbf{geheugengebruik}.
\\ \\
Een volgende optie die we verkend hebben zijn \textbf{suffix arrays}.
Na testen bleek dat deze datastructuur ons een goeie \textbf{balans gaf tussen snelheid en geheugengebruik}.
Aan de hand hiervan zijn we erin geslaagd een nieuwe indexstructuur voor UniProtKB op te bouwen die de huidige Unipept-index volledig kan vervangen, en alle bovenstaande doelstellingen haalt.
Aan de hand van een aangepast zoeksysteem ondersteunen we zowel exacte als semi-exacte matching, waarbij efficiënt alle informatie van de gematchte peptiden teruggegeven kan worden.
Het grootste nadeel van deze manier van werken is dat de functionele en taxonomische analyses van Unipept \textit{on the fly} moeten gebeuren.
Ondanks dit nadeel, is de nieuwe versie van Unipept 6.0 10 tot 100 maal sneller dan Unipept 5.x wanneer beide indices \textit{missed cleavages} verwerken.
Wanneer \textit{advanced missed cleavages handling} uitgezet wordt op Unipept 5.x, is Unipept 6.x slechts een fractie trager.
Dit wil zeggen dat Unipept 6.x willekeurige peptiden (al dan niet tryptisch of met \textit{missed cleavages}) kan verwerken in ongeveer dezelfde tijd die Unipept 5.x nodig heeft om enkel strikt tryptische peptiden te verwerken.
\\ \\
Als derde en vierde indexstructuur hebben we kort de \textbf{FM-index en R-index} getest.
Na enkele testen bleek al snel dat het \textbf{geheugengebruik} tijdens het bouwen \textbf{dubbel zo hoog lag} als bij suffix arrays.
Daarom hebben we deze opties niet verder uitgewerkt, ook al hebben beide indices interessante eigenschappen voor ons probleem.
Zo laten bidirectionele FM-indices toe om algemenere inexacte matching uit te voeren en de index verder te verkleinen, en is de resulterende index bij R-indices kleiner door het gebruik van run-length encoding.

\section{Toekomstig werk}
Ondanks dat we een index hebben kunnen bouwen die de huidige Unipept index kan vervangen, en willekeurige peptiden kan vinden in plaats van enkel tryptische peptiden, zijn er meerdere plaatsen waar nog extra onderzoek kan gebeuren.
\\ \\
De gemakkelijkste, en meest directe verbetering is het verder \textbf{verkleinen van de resulterende index}.
UniProt 2023\_04 bevat ongeveer 86.8 miljard aminozuren, waardoor we dus ook evenveel verschillende getallen moeten kunnen voorstellen in de suffix array.
Aangezien $86.8 \cdot 10^9 > 2^{32}$ maken we gebruik van 64-bit integers.
Hiermee kunnen we echter veel te veel verschillende getallen voorstellen.
In de praktijk hebben we slechts nood aan $1 + \lfloor \log_2(86.8 \cdot 10^9) \rfloor = 37$ bits per waarde in de suffix array.
Aangezien de huidige sparse suffix array (met sparseness factor $k = 3$) ongeveer 235 GB groot is, zou de SSA na deze aanpassing slechts 136 GB groot zijn.
Bij de tekst kunnen we dezelfde aanpassing maken.
Daar hebben we 26 + 2 = 28 verschillende tekens, wat aan de hand van 5 bits voorgesteld kan worden.
Aangezien de huidige tekst ongeveer 88 GB groot is, zou dit resulteren in een tekst die slechts $88 \cdot \frac{5}{8} \approx 55$ GB groot is.
Hierbij komt nog taxonomische en functionele informatie in combinatie met de UniProt accession numbers en de suffix naar proteïne mapping.
Hierdoor zou de totale resulterende index van $235 + 88 + 23 = 346$ GB naar $136 + 55 + 23 = 214$ GB gaan, wat iets meer dan \textbf{33\% winst} oplevert.
Merk op dat dit de nodige hoeveelheid geheugen tijdens het opbouwen niet verkleint, aangezien we in die fase wel gebruik moeten maken van 64-bit integers en 8-bit karakters.
Door deze manier van compressie te gebruiken zou het ook mogelijk worden om sparseness factor $k = 2$ te gebruiken op de Unipept servers.
In het totaal zou de index dan $353 \cdot \frac{37}{64} + 55 + 23 \approx 282$ GB groot zijn, wat comfortabel in 0.5 TB RAM past.
Ondanks de overhead die de compressie introduceert, kan de performantie op deze manier mogelijk toch nog verbeterd worden.
Bovendien zullen hierdoor ook peptiden die slechts uit twee aminozuren bestaan, gematcht kunnen worden aan de hand van de SSA\@.
\\ \\
Ook tijdens het opbouwen van de SA zijn er nog interessante pistes om te verkennen.
Zo zou het extreem voordelig zijn om een manier te vinden om de suffix array onmiddellijk \textbf{sparse te maken tijdens het opbouwen}.
Hierbij zal het bovendien belangrijk zijn dat deze implementatie een \textbf{lage constante factor heeft op vlak van geheugengebruik}.
Indien deze constante vrij groot is, zal de winst verloren gaan ten opzichte van de huidige implementatie, aangezien we altijd een kleine sparseness factor $k$ gebruiken.
Als alternatief kunnen we mogelijk het maximale geheugengebruik beperken via een online algoritme.
Zo kan tijdens het opbouwen één proteïne per keer toegevoegd worden aan de suffix array, maar kunnen we nieuwere UniProtKB releases ook efficiënt afhandelen door te vertrekken van de index uit de vorige release.
\\ \\
Een derde punt van verbetering zit in het \textbf{berekenen van de LCA*}.
Indien deze voorberekend wordt tijdens het opbouwen van de index, zal dit niet enkel de performantie ten goede komen, het zal ook de nood voor de drempelwaarde B (die standaard op 10\thinspace000 staat) sterk verminderen.
De meest duidelijke piste hiervoor is aan de hand van Enhanced Suffix Arrays (ESAs).
In deze masterproef hebben we deze piste niet verder verkend vanwege de eerste indicatie dat het berekenen van de extra tabellen het geheugenverbruik zou verdubbelen, en dat het \textit{on the fly} berekenen van de analyses een acceptabele overhead met zich meebrengt.
\\ \\
Een vierde mogelijke route is het \textbf{uitbreiden van de inexacte matching}.
Op dit moment is dit slechts in een extreem beperkte vorm aanwezig.
We hebben namelijk enkel de optie om I en L aan elkaar gelijk te stellen.
Tools zoals de eerder vermelde Expasy ScanProsite tool ondersteunen verschillende manieren om inexacte matching uit te voeren.
Zo zouden we ondersteuning voor karakterklassen, een reeks van herhalingen (al dan niet met een minimum en maximum bereik) en wildcards kunnen toevoegen.
Gelijkaardig aan hoe \textit{livegrep}~\cite{livegrep} gebruikmaakt van Google's RE2~\cite{re2} regex engine en meerdere suffix arrays~\cite{regex_sa}.
Een andere manier van inexacte matching kan zijn via het toelaten van maximaal $x$ mismatches.
Op deze manier kan men ook omgaan met kleine mutaties die ontstaan in proteïnen, of kleine variaties die ontstaan bij het omzetten van spectra naar aminozuursequenties.
Over deze laatste vorm van inexacte matching is door het team van Unipept een vervolgmasterproef uitgeschreven om dit volgend jaar te verkennen.
Hierbij zal verder ingegaan worden op FM-index en R-index.